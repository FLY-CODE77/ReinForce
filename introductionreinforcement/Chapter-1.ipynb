{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defensive-speed",
   "metadata": {},
   "source": [
    "> The Reinforcement Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-discretion",
   "metadata": {},
   "source": [
    "# Elements of Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-vietnam",
   "metadata": {},
   "source": [
    "- policy\n",
    "- reward signal\n",
    "- value function \n",
    "- model of the enviroment(optionally)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-conditioning",
   "metadata": {},
   "source": [
    "### policy \n",
    "    + learning agent's way of behaving at a given time\n",
    "    + Roughly speaking \n",
    "        - Policy is a mapping from perceived states of enviroment  \n",
    "        - to actions to be taken when in those states\n",
    "        \n",
    "- simular as stimulus-response rules\n",
    "--- \n",
    "- some case the policy may be simple function or lookup table\n",
    "- others may involve extensive computation \n",
    "---\n",
    "- determine behavior \n",
    "- In general policies may be stochastic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-bernard",
   "metadata": {},
   "source": [
    "### reward signal\n",
    "- Goal in reinforcemnet learning problem\n",
    "- each time step,\n",
    "    - enviroment sends to agent a single number --> reward\n",
    "- Agent sole objective is maximize the total reward \n",
    "---\n",
    "- The reward signal defines what are the good and bad events for the agent \n",
    "- In biological system - reward is same as apin and pleasure \n",
    "---\n",
    "- The only way the agent can influence the reward signal is through the action\n",
    "---\n",
    "- The reward signal is primary basis for altering the policy \n",
    "- If selected policy is followed by low reward \n",
    "- then the policy may be changed\n",
    "- In general reward signals may be stochastic function \n",
    "- Of the enviroment and the actions taken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-search",
   "metadata": {},
   "source": [
    "### value function\n",
    "- wherea reward signal indicates what is good in immediate sense\n",
    "- **value function** specifies what is good in the long run\n",
    "---\n",
    "- Roughly speaking\n",
    "    - the value of a state is the total amount of reward \n",
    "    - agent can expect to accumulate over the future \n",
    "    - starting from that state \n",
    "---\n",
    "- values indicate the long-term desirability of states "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-patient",
   "metadata": {},
   "source": [
    "- Without rewards there could be no values,\n",
    "- only purpose of estimating values is to achieve more reward\n",
    "---\n",
    "**But**\n",
    "\n",
    "- Action choices are made based on value judgments\n",
    "- We seek actions obtain the greatest amount value\n",
    "- Not highest reward "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-oliver",
   "metadata": {},
   "source": [
    "### model of the enviroment \n",
    "- mimics the behavior of the environmnet \n",
    "- it allows inferences to be made a about how environmnet will behave\n",
    "---\n",
    "- Models are used for planning \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-affair",
   "metadata": {},
   "source": [
    "# Limitations and Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-consumption",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
